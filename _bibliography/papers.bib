---
---
@article{CRAGCUPKDD2024,
  abbr={Workshop Paper},
  title={2024 KDD Cup CRAG Workshop: UM6P Team Technical Report},
  abstract= {Large Language Models (LLMs) have shown impressive capabilities in understanding and generating coherent natural language, but they still suffer from hallucinations, i.e. answers that seem coherent but are incorrect. Retrieval-Augmented Generation (RAG) aims at reducing hallucinations by grounding the LLMs with external relevant data sources. The Meta KDD Cup 2024 introduced the Comprehensive RAG (CRAG) challenge, which evaluates Question-Answering (QA) systems across five domains and eight question types. The challenge consists of three tasks: Web-Based Retrieval Summarization, Knowledge Graph and Web Augmentation, and End-to-End RAG. This paper summarizes the UM6P Teamâ€™s participation in the first task. We describe our experimental framework including hyperparameter tuning, sampling strategy selection (tobest align the offline and online results), and an extensive evaluation of various RAG pipelines. We also share key insights about the contribution of each RAG component to the overall performance, covering chunking, retrieval, and enhancement techniques. The pipelines were assessed offline using Llama 3 and online using GPT-4 based on the number of correct answers, missing answers, and hallucinations. Our experiments indicate that the best-performing pipeline consists of Facebook AI Similarity Search (FAISS), sentence chunking, re-ranking, and Hypothetical Document Embedding for input enhancement (HyDE), achieving a competitive accuracy score of 0.339 compared to the top score of 0.393, despite a lower overall CRAG score (0.05 vs. 0.204) due to hallucinations (0.288 vs. 0.189). We conclude with a discussion of the main technical and performance challenges encountered during the competition, and some pointers on future research directions.},
  journal={Technical Report accepted to 2024 KDD Cup CRAG Workshop, detailing some analysis and approaches to build a RAG system for QA using web pages during our participation in KDD CRAG Comptetion},
  year={2024},
  html={https://openreview.net/forum?id=k1cnnNbB3f},
  pdf={https://openreview.net/pdf?id=k1cnnNbB3f},
  selected={true},
  preview={wave-mechanics.gif}
}

@article{AMONUSEGMICCAI2024,
  abbr={Conference Paper},
  title={AMONuSeg: A dataset of African Multi-Organ Nuclei Semantic Segmentation of H&E-Stained Histological Images},
  abstract= {Nuclei semantic segmentation is a key component for advancing machine learning and deep learning applications in digital pathology. However, most existing segmentation models are trained and tested on high-quality data acquired with expensive equipment, such as whole slide scanners, which are not accessible to most pathologists in developing countries. These pathologists rely on low-resource data acquired with low-precision microscopes, smartphones, or digital cameras, which have different characteristics and challenges than high-resource data. Therefore, there is a gap between the state-of-the-art segmentation models and the real-world needs of low-resource settings. This work aims to bridge this gap by presenting the first fully annotated African multi-organ dataset for histopathology nuclei semantic segmentation acquired with a low-precision microscope. We also evaluate state-of-the-art segmentation models, including spectral feature extraction encoder and vision transformer-based models, and stain normalization techniques for color normalization of Hematoxylin and Eosin-stained histopathology slides.Our results provide important insights for future research on nuclei histopathology segmentation with low-resource data. Code and dataset:https://github.com/zerouaoui/AMONUSEG},
  journal={Accepted to 27th internation conference on Medical Imaging Computing and Computer Assisted Intervention},
  publisher=aps,
  year={2024},
  doi={https://doi.org/10.1007/978-3-031-72114-4_10},
  html={https://github.com/zerouaoui/AMONUSEG},
  pdf={https://papers.miccai.org/miccai-2024/paper/2801_paper.pdf},
  selected={true},
  preview={wave-mechanics.gif}
}
